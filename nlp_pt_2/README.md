Continutation of nlp_pt_1

NLP with deep learning

* note 1: word2vec section is unrefined and unoptimized when it comes to training. goal was just to practice implementation. 
* note 2: word2vec and GloVe only implemented in numpy.

**Focus:**
- Markov models extended to neural nets
- continuous bag of words 
- skip-gram + word2vec
- GloVe 
- various RNN architectures for NLP usage
- HMM for NLP usage (where hidden states are known, so no training is simply counting states and no expectation-maximization)  
